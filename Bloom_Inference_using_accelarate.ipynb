{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pushkarraj/My_experiments/blob/main/Bloom_Inference_using_accelarate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23Nr2_r1inbk",
        "outputId": "d0321b01-575f-461d-d58c-b7fe2bf7b6cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n03OfRlFjQnz",
        "outputId": "196d4338-30a7-4837-9a42-ef5ae940ea93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Paraphrasing\n",
            "\u001b[0m\u001b[01;34mbloom17bhuge50k5ep\u001b[0m/\n",
            "\u001b[01;34mbloom_sharded\u001b[0m/\n",
            "cached_lm_BloomTokenizerFast_256_Master_train.txt\n",
            "cached_lm_BloomTokenizerFast_256_Master_train.txt.lock\n",
            "cached_lm_BloomTokenizerFast_256_Master_val.txt\n",
            "cached_lm_BloomTokenizerFast_256_Master_val.txt.lock\n",
            "cached_lm_GPT2Tokenizer_255_Master_train.txt\n",
            "cached_lm_GPT2Tokenizer_255_Master_train.txt.lock\n",
            "cached_lm_GPT2Tokenizer_255_Master_val.txt\n",
            "cached_lm_GPT2Tokenizer_255_Master_val.txt.lock\n",
            "gpt3_para_data1.csv\n",
            "Master_Gpt3_output.csv\n",
            "Master_train.txt\n",
            "Master_val.txt\n",
            "new.txt\n",
            "requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/Paraphrasing\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfpRAF05jSyi",
        "outputId": "893bd3c7-abd9-4fec-decf-d2ba57f90087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet -r requirements.txt\n",
        "#!pip install --quiet datasets\n",
        "!pip install --quiet git+https://github.com/huggingface/accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pVDbkfDUjcyl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoModelForCausalLM,AutoConfig,AutoTokenizer,BloomForCausalLM,pipeline\n",
        "from accelerate import Accelerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5G1ZrnMkMul"
      },
      "outputs": [],
      "source": [
        "def cleanup():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "cleanup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpmVpDenvtte"
      },
      "outputs": [],
      "source": [
        "accelerator = Accelerator()\n",
        "device = accelerator.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWl25yzu_Dp9"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "checkpoint = \"/content/drive/MyDrive/Colab Notebooks/Paraphrasing/bloom17bhuge50k5ep/model\"\n",
        "\n",
        "model = BloomForCausalLM.from_pretrained(checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHt3IWXxDeju"
      },
      "outputs": [],
      "source": [
        "#Run when you need to shard the models otherwise no need\n",
        "import json\n",
        "import os\n",
        "\n",
        "if not os.path.exists('bloom_sharded'):\n",
        "   os.makedirs('bloom_sharded')\n",
        "path=os.getcwd()\n",
        "model.save_pretrained('bloom_sharded', max_shard_size=\"2GB\")\n",
        "with open(os.path.join('bloom_sharded', \"pytorch_model.bin.index.json\"), \"r\") as f:\n",
        "  index = json.load(f)\n",
        "\n",
        "print(index.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NURnDrZNUtlf",
        "outputId": "957f4a10-6e40-4558-af91-d717255aad25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lm_head.weight': 'pytorch_model-00006-of-00006.bin',\n",
              " 'transformer.h.0.input_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.0.input_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.0.mlp.dense_4h_to_h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.0.mlp.dense_4h_to_h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.0.mlp.dense_h_to_4h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.0.mlp.dense_h_to_4h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.0.post_attention_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.0.post_attention_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.0.self_attention.dense.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.0.self_attention.dense.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.0.self_attention.query_key_value.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.0.self_attention.query_key_value.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.1.input_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.1.input_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.1.mlp.dense_4h_to_h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.1.mlp.dense_4h_to_h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.1.mlp.dense_h_to_4h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.1.mlp.dense_h_to_4h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.1.post_attention_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.1.post_attention_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.1.self_attention.dense.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.1.self_attention.dense.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.1.self_attention.query_key_value.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.1.self_attention.query_key_value.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.10.input_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.10.input_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.10.mlp.dense_4h_to_h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.10.mlp.dense_4h_to_h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.10.mlp.dense_h_to_4h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.10.mlp.dense_h_to_4h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.10.post_attention_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.10.post_attention_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.10.self_attention.dense.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.10.self_attention.dense.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.10.self_attention.query_key_value.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.10.self_attention.query_key_value.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.11.input_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.11.input_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.11.mlp.dense_4h_to_h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.11.mlp.dense_4h_to_h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.11.mlp.dense_h_to_4h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.11.mlp.dense_h_to_4h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.11.post_attention_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.11.post_attention_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.11.self_attention.dense.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.11.self_attention.dense.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.11.self_attention.query_key_value.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.11.self_attention.query_key_value.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.12.input_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.12.input_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.12.mlp.dense_4h_to_h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.12.mlp.dense_4h_to_h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.12.mlp.dense_h_to_4h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.12.mlp.dense_h_to_4h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.12.post_attention_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.12.post_attention_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.12.self_attention.dense.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.12.self_attention.dense.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.12.self_attention.query_key_value.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.12.self_attention.query_key_value.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.13.input_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.13.input_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.13.mlp.dense_4h_to_h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.13.mlp.dense_4h_to_h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.13.mlp.dense_h_to_4h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.13.mlp.dense_h_to_4h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.13.post_attention_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.13.post_attention_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.13.self_attention.dense.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.13.self_attention.dense.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.13.self_attention.query_key_value.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.13.self_attention.query_key_value.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.14.input_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.14.input_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.14.mlp.dense_4h_to_h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.14.mlp.dense_4h_to_h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.14.mlp.dense_h_to_4h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.14.mlp.dense_h_to_4h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.14.post_attention_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.14.post_attention_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.14.self_attention.dense.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.14.self_attention.dense.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.14.self_attention.query_key_value.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.14.self_attention.query_key_value.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.15.input_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.15.input_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.15.mlp.dense_4h_to_h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.15.mlp.dense_4h_to_h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.15.mlp.dense_h_to_4h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.15.mlp.dense_h_to_4h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.15.post_attention_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.15.post_attention_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.15.self_attention.dense.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.15.self_attention.dense.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.15.self_attention.query_key_value.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.15.self_attention.query_key_value.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.16.input_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.16.input_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.16.mlp.dense_4h_to_h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.16.mlp.dense_4h_to_h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.16.mlp.dense_h_to_4h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.16.mlp.dense_h_to_4h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.16.post_attention_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.16.post_attention_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.16.self_attention.dense.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.16.self_attention.dense.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.16.self_attention.query_key_value.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.16.self_attention.query_key_value.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.17.input_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.17.input_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.17.mlp.dense_4h_to_h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.17.mlp.dense_4h_to_h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.17.mlp.dense_h_to_4h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.17.mlp.dense_h_to_4h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.17.post_attention_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.17.post_attention_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.17.self_attention.dense.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.17.self_attention.dense.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.17.self_attention.query_key_value.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.17.self_attention.query_key_value.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.18.input_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.18.input_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.18.mlp.dense_4h_to_h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.18.mlp.dense_4h_to_h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.18.mlp.dense_h_to_4h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.18.mlp.dense_h_to_4h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.18.post_attention_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.18.post_attention_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.18.self_attention.dense.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.18.self_attention.dense.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.18.self_attention.query_key_value.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.18.self_attention.query_key_value.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.19.input_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.19.input_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.19.mlp.dense_4h_to_h.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.19.mlp.dense_4h_to_h.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.19.mlp.dense_h_to_4h.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.19.mlp.dense_h_to_4h.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.19.post_attention_layernorm.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.19.post_attention_layernorm.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.19.self_attention.dense.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.19.self_attention.dense.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.19.self_attention.query_key_value.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.19.self_attention.query_key_value.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.2.input_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.2.input_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.2.mlp.dense_4h_to_h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.2.mlp.dense_4h_to_h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.2.mlp.dense_h_to_4h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.2.mlp.dense_h_to_4h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.2.post_attention_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.2.post_attention_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.2.self_attention.dense.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.2.self_attention.dense.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.2.self_attention.query_key_value.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.2.self_attention.query_key_value.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.20.input_layernorm.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.20.input_layernorm.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.20.mlp.dense_4h_to_h.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.20.mlp.dense_4h_to_h.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.20.mlp.dense_h_to_4h.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.20.mlp.dense_h_to_4h.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.20.post_attention_layernorm.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.20.post_attention_layernorm.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.20.self_attention.dense.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.20.self_attention.dense.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.20.self_attention.query_key_value.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.20.self_attention.query_key_value.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.21.input_layernorm.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.21.input_layernorm.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.21.mlp.dense_4h_to_h.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.21.mlp.dense_4h_to_h.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.21.mlp.dense_h_to_4h.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.21.mlp.dense_h_to_4h.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.21.post_attention_layernorm.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.21.post_attention_layernorm.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.21.self_attention.dense.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.21.self_attention.dense.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.21.self_attention.query_key_value.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.21.self_attention.query_key_value.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.22.input_layernorm.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.22.input_layernorm.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.22.mlp.dense_4h_to_h.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.22.mlp.dense_4h_to_h.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.22.mlp.dense_h_to_4h.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.22.mlp.dense_h_to_4h.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.22.post_attention_layernorm.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.22.post_attention_layernorm.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.22.self_attention.dense.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.22.self_attention.dense.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.22.self_attention.query_key_value.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.22.self_attention.query_key_value.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.23.input_layernorm.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.23.input_layernorm.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.23.mlp.dense_4h_to_h.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.23.mlp.dense_4h_to_h.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.23.mlp.dense_h_to_4h.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.23.mlp.dense_h_to_4h.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.23.post_attention_layernorm.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.23.post_attention_layernorm.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.23.self_attention.dense.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.23.self_attention.dense.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.23.self_attention.query_key_value.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.23.self_attention.query_key_value.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.h.3.input_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.3.input_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.3.mlp.dense_4h_to_h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.3.mlp.dense_4h_to_h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.3.mlp.dense_h_to_4h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.3.mlp.dense_h_to_4h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.3.post_attention_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.3.post_attention_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.3.self_attention.dense.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.3.self_attention.dense.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.3.self_attention.query_key_value.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.3.self_attention.query_key_value.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.4.input_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.4.input_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.4.mlp.dense_4h_to_h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.4.mlp.dense_4h_to_h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.4.mlp.dense_h_to_4h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.4.mlp.dense_h_to_4h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.4.post_attention_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.4.post_attention_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.4.self_attention.dense.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.4.self_attention.dense.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.4.self_attention.query_key_value.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.4.self_attention.query_key_value.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.5.input_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.5.input_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.5.mlp.dense_4h_to_h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.5.mlp.dense_4h_to_h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.5.mlp.dense_h_to_4h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.5.mlp.dense_h_to_4h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.5.post_attention_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.5.post_attention_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.5.self_attention.dense.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.5.self_attention.dense.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.5.self_attention.query_key_value.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.5.self_attention.query_key_value.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.6.input_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.6.input_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.6.mlp.dense_4h_to_h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.6.mlp.dense_4h_to_h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.6.mlp.dense_h_to_4h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.6.mlp.dense_h_to_4h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.6.post_attention_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.6.post_attention_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.6.self_attention.dense.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.6.self_attention.dense.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.6.self_attention.query_key_value.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.6.self_attention.query_key_value.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.7.input_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.7.input_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.7.mlp.dense_4h_to_h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.7.mlp.dense_4h_to_h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.7.mlp.dense_h_to_4h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.7.mlp.dense_h_to_4h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.7.post_attention_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.7.post_attention_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.7.self_attention.dense.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.7.self_attention.dense.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.7.self_attention.query_key_value.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.7.self_attention.query_key_value.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.8.input_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.8.input_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.8.mlp.dense_4h_to_h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.8.mlp.dense_4h_to_h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.8.mlp.dense_h_to_4h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.8.mlp.dense_h_to_4h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.8.post_attention_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.8.post_attention_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.8.self_attention.dense.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.8.self_attention.dense.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.8.self_attention.query_key_value.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.8.self_attention.query_key_value.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.9.input_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.9.input_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.9.mlp.dense_4h_to_h.bias': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.9.mlp.dense_4h_to_h.weight': 'pytorch_model-00004-of-00006.bin',\n",
              " 'transformer.h.9.mlp.dense_h_to_4h.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.9.mlp.dense_h_to_4h.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.9.post_attention_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.9.post_attention_layernorm.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.9.self_attention.dense.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.9.self_attention.dense.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.9.self_attention.query_key_value.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.h.9.self_attention.query_key_value.weight': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.ln_f.bias': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.ln_f.weight': 'pytorch_model-00005-of-00006.bin',\n",
              " 'transformer.word_embeddings.weight': 'pytorch_model-00002-of-00006.bin',\n",
              " 'transformer.word_embeddings_layernorm.bias': 'pytorch_model-00003-of-00006.bin',\n",
              " 'transformer.word_embeddings_layernorm.weight': 'pytorch_model-00003-of-00006.bin'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open(os.path.join('bloom_sharded', \"pytorch_model.bin.index.json\"), \"r\") as f:\n",
        "  index = json.load(f)\n",
        "\n",
        "index['weight_map']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Z5n0oK65Gxj"
      },
      "outputs": [],
      "source": [
        "from accelerate import init_empty_weights,infer_auto_device_map\n",
        "\n",
        "checkpoint = \"/content/drive/MyDrive/Colab Notebooks/Paraphrasing/bloom17bhuge50k5ep/model\"\n",
        "#checkpoint= \"/content/drive/MyDrive/Colab Notebooks/Paraphrasing/bloom_sharded\"\n",
        "config = AutoConfig.from_pretrained(checkpoint,device_map=\"auto\")\n",
        "\n",
        "with init_empty_weights():\n",
        "    model = AutoModelForCausalLM.from_config(config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_map = infer_auto_device_map(\n",
        "    model, \n",
        "    no_split_module_classes=[\"BloomBlock\"]\n",
        ")"
      ],
      "metadata": {
        "id": "NXsRbYhJalAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_device_map= {'transformer.word_embeddings': 0,\n",
        " 'transformer.word_embeddings_layernorm': 0,\n",
        " 'transformer.h.0': 0,\n",
        " 'transformer.h.1': 0,\n",
        " 'transformer.h.2': 0,\n",
        " 'transformer.h.3': 0,\n",
        " 'transformer.h.4': 0,\n",
        " 'transformer.h.5': 0,\n",
        " 'transformer.h.6': 0,\n",
        " 'transformer.h.7': 0,\n",
        " 'transformer.h.8': 0,\n",
        " 'transformer.h.9': 0,\n",
        " 'transformer.h.10': 0,\n",
        " 'transformer.h.11': 0,\n",
        " 'transformer.h.12': 0,\n",
        " 'transformer.h.13': 0,\n",
        " 'transformer.h.14': 0,\n",
        " 'transformer.h.15': 0,\n",
        " 'transformer.h.16': 0,\n",
        " 'transformer.h.17': 0,\n",
        " 'transformer.h.18': 0,\n",
        " 'transformer.h.19': 0,\n",
        " 'transformer.h.20': 0,\n",
        " 'transformer.h.21': 0,\n",
        " 'transformer.h.22': 0,\n",
        " 'transformer.h.23': 0,\n",
        " 'transformer.ln_f': 0,\n",
        " 'lm_head': 0}"
      ],
      "metadata": {
        "id": "8yba6vn9c82H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YndcfQgR5nkP"
      },
      "outputs": [],
      "source": [
        "from accelerate import load_checkpoint_and_dispatch\n",
        "t= \"/content/drive/MyDrive/Colab Notebooks/Paraphrasing/bloom_sharded\"\n",
        "model_new = load_checkpoint_and_dispatch(model,t, device_map=my_device_map, no_split_module_classes=[\"BloomBlock\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_new.hf_device_map"
      ],
      "metadata": {
        "id": "KBMwMnkYiNvg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12c6e883-4183-44a1-acd3-57d147dda4d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'transformer.word_embeddings': 0,\n",
              " 'transformer.word_embeddings_layernorm': 0,\n",
              " 'transformer.h.0': 0,\n",
              " 'transformer.h.1': 0,\n",
              " 'transformer.h.2': 0,\n",
              " 'transformer.h.3': 0,\n",
              " 'transformer.h.4': 0,\n",
              " 'transformer.h.5': 0,\n",
              " 'transformer.h.6': 0,\n",
              " 'transformer.h.7': 0,\n",
              " 'transformer.h.8': 0,\n",
              " 'transformer.h.9': 0,\n",
              " 'transformer.h.10': 0,\n",
              " 'transformer.h.11': 0,\n",
              " 'transformer.h.12': 0,\n",
              " 'transformer.h.13': 0,\n",
              " 'transformer.h.14': 0,\n",
              " 'transformer.h.15': 0,\n",
              " 'transformer.h.16': 0,\n",
              " 'transformer.h.17': 0,\n",
              " 'transformer.h.18': 0,\n",
              " 'transformer.h.19': 0,\n",
              " 'transformer.h.20': 0,\n",
              " 'transformer.h.21': 0,\n",
              " 'transformer.h.22': 0,\n",
              " 'transformer.h.23': 0,\n",
              " 'transformer.ln_f': 0,\n",
              " 'lm_head': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLqaBWW2l6n4"
      },
      "outputs": [],
      "source": [
        "#model = BloomForCausalLM.from_pretrained('/content/drive/MyDrive/Colab Notebooks/Paraphrasing/bloom17bhuge50k5ep/model').to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained('bigscience/bloom-1b7',truncation=True,padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxR1xS_2je2N"
      },
      "outputs": [],
      "source": [
        "model = accelerator.prepare(model_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6xchM1AGshF",
        "outputId": "6b3e30d2-811d-4e89-89de-7b881d038599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am a web developer with significant understanding of developing, developing, improving, and redesigning websites and mobile APPS.\n"
          ]
        }
      ],
      "source": [
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "sentence = \"I am a web developer with extensive knowledge of developing, enhancing, maintaining, and redesigning websites and mobile APPS.\"\n",
        "#sentence=\"I am Shiv from 'appnox technologies'.\"\n",
        "#sentence=\"I am a boy\"\n",
        "text =  \"<s>\"+ sentence + \"</s>>>>><p>\"\n",
        "\n",
        "encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\",truncation=True)\n",
        "input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
        "\n",
        "outputs = model.generate(\n",
        "    input_ids=input_ids, attention_mask=attention_masks,\n",
        "    max_length=256,\n",
        "    temperature=0.7,\n",
        "    do_sample=True,\n",
        "    top_k=100,\n",
        "    top_p=0.95,\n",
        "    early_stopping=True,\n",
        ")\n",
        "\n",
        "for output in outputs:\n",
        "    line = tokenizer.decode(output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "    #print(line)\n",
        "    print(line.split(\">>>><p>\")[1].split(\"</p>\")[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lmlYXeOGs0q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPNNE1x8AsElbY4DjptpRNb",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}